@InProceedings{Li_2020_CVPR,
    author = {Li, Shichao and Ke, Lei and Pratama, Kevin and Tai, Yu-Wing and Tang, Chi-Keung and Cheng, Kwang-Ting},
    title = {Cascaded Deep Monocular 3D Human Pose Estimation With Evolutionary Training Data},
    booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2020}
}

@InProceedings{Akhter_2015_CVPR,
    author = {Akhter, Ijaz and Black, Michael J.},
    title = {Pose-Conditioned Joint Angle Limits for 3D Human Pose Reconstruction},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2015}
}

@article{h36m_pami,
    author = {Ionescu, Catalin and Papava, Dragos and Olaru, Vlad and Sminchisescu, Cristian},
    title = {Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    publisher = {IEEE Computer Society},
    year = {2014}
}

@article{DBLP:journals/corr/PavlakosZDD16,
    author = {Georgios Pavlakos and
 Xiaowei Zhou and
 Konstantinos G. Derpanis and
 Kostas Daniilidis},
    title = {Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose},
    journal = {CoRR},
    volume = {abs/1611.07828},
    year = {2016},
    url = {http://arxiv.org/abs/1611.07828},
    archivePrefix = {arXiv},
    eprint = {1611.07828},
    timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
    biburl = {https://dblp.org/rec/journals/corr/PavlakosZDD16.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1710-06513,
    author = {Haoshu Fang and
 Yuanlu Xu and
 Wenguan Wang and
 Xiaobai Liu and
 Song{-}Chun Zhu},
    title = {Learning Knowledge-guided Pose Grammar Machine for 3D Human Pose Estimation},
    journal = {CoRR},
    volume = {abs/1710.06513},
    year = {2017},
    url = {http://arxiv.org/abs/1710.06513},
    archivePrefix = {arXiv},
    eprint = {1710.06513},
    timestamp = {Sat, 23 Jan 2021 01:20:29 +0100},
    biburl = {https://dblp.org/rec/journals/corr/abs-1710-06513.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1903-02330,
    author = {Muhammed Kocabas and
 Salih Karagoz and
 Emre Akbas},
    title = {Self-Supervised Learning of 3D Human Pose using Multi-view Geometry},
    journal = {CoRR},
    volume = {abs/1903.02330},
    year = {2019},
    url = {http://arxiv.org/abs/1903.02330},
    archivePrefix = {arXiv},
    eprint = {1903.02330},
    timestamp = {Sun, 31 Mar 2019 19:01:24 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1903-02330.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ghosh_learning_2017,
    title = {Learning {Human} {Motion} {Models} for {Long}-term {Predictions}},
    url = {http://arxiv.org/abs/1704.02827},
    abstract = {We propose a new architecture for the learning of predictive spatio-temporal motion models from data alone. Our approach, dubbed the Dropout Autoencoder LSTM (DAELSTM), is capable of synthesizing natural looking motion sequences over long-time horizons1 without catastrophic drift or motion degradation. The model consists of two components, a 3-layer recurrent neural network to model temporal aspects and a novel autoencoder that is trained to implicitly recover the spatial structure of the human skeleton via randomly removing information about joints during training. This Dropout Autoencoder (DAE) is then used to ﬁlter each predicted pose by a 3-layer LSTM network, reducing accumulation of correlated error and hence drift over time. Furthermore to alleviate insufﬁciency of commonly used quality metric, we propose a new evaluation protocol using action classiﬁers to assess the quality of synthetic motion sequences. The proposed protocol can be used to assess quality of generated sequences of arbitrary length. Finally, we evaluate our proposed method on two of the largest motion-capture datasets available and show that our model outperforms the state-of-the-art techniques on a variety of actions, including cyclic and acyclic motion, and that it can produce natural looking sequences over longer time horizons than previous methods.},
    language = {en},
    urldate = {2021-06-18},
    journal = {arXiv:1704.02827 [cs]},
    author = {Ghosh, Partha and Song, Jie and Aksan, Emre and Hilliges, Otmar},
    month = dec,
    year = {2017},
    note = {arXiv: 1704.02827},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
    file = {Ghosh et al. - 2017 - Learning Human Motion Models for Long-term Predict.pdf:/home/rafael/Zotero/storage/FK3PZHAS/Ghosh et al. - 2017 - Learning Human Motion Models for Long-term Predict.pdf:application/pdf}
}

@article{sun_integral_2018,
    title = {An {Integral} {Pose} {Regression} {System} for the {ECCV2018} {PoseTrack} {Challenge}},
    url = {http://arxiv.org/abs/1809.06079},
    abstract = {For the ECCV 2018 PoseTrack Challenge, we present a 3D human pose estimation system based mainly on the integral human pose regression method. We show a comprehensive ablation study to examine the key performance factors of the proposed system. Our system obtains 47mm MPJPE on the CHALL H80K test dataset, placing second in the ECCV2018 3D human pose estimation challenge. Code will be released to facilitate future work.},
    language = {en},
    urldate = {2021-06-18},
    journal = {arXiv:1809.06079 [cs]},
    author = {Sun, Xiao and Li, Chuankang and Lin, Stephen},
    month = sep,
    year = {2018},
    note = {arXiv: 1809.06079},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
    file = {Sun et al. - 2018 - An Integral Pose Regression System for the ECCV201.pdf:/home/rafael/Zotero/storage/S74J6LX9/Sun et al. - 2018 - An Integral Pose Regression System for the ECCV201.pdf:application/pdf}
}

@article{sun_integral_2018-1,
    title = {Integral {Human} {Pose} {Regression}},
    url = {http://arxiv.org/abs/1711.08229},
    abstract = {State-of-the-art human pose estimation methods are based on heat map representation. In spite of the good performance, the representation has a few issues in nature, such as non-diﬀerentiable postprocessing and quantization error. This work shows that a simple integral operation relates and uniﬁes the heat map representation and joint regression, thus avoiding the above issues. It is diﬀerentiable, eﬃcient, and compatible with any heat map based methods. Its eﬀectiveness is convincingly validated via comprehensive ablation experiments under various settings, speciﬁcally on 3D pose estimation, for the ﬁrst time.},
    language = {en},
    urldate = {2021-06-18},
    journal = {arXiv:1711.08229 [cs]},
    author = {Sun, Xiao and Xiao, Bin and Wei, Fangyin and Liang, Shuang and Wei, Yichen},
    month = sep,
    year = {2018},
    note = {arXiv: 1711.08229},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
    file = {Sun et al. - 2018 - Integral Human Pose Regression.pdf:/home/rafael/Zotero/storage/MLXLFXZR/Sun et al. - 2018 - Integral Human Pose Regression.pdf:application/pdf}
}

@article{sun_compositional_2017,
    title = {Compositional {Human} {Pose} {Regression}},
    url = {http://arxiv.org/abs/1704.00159},
    abstract = {Regression based methods are not performing as well as detection based methods for human pose estimation. A central problem is that the structural information in the pose is not well exploited in the previous regression methods. In this work, we propose a structure-aware regression approach. It adopts a reparameterized pose representation using bones instead of joints. It exploits the joint connection structure to deﬁne a compositional loss function that encodes the long range interactions in the pose. It is simple, effective, and general for both 2D and 3D pose estimation in a uniﬁed setting. Comprehensive evaluation validates the effectiveness of our approach. It signiﬁcantly advances the state-of-the-art on Human3.6M [20] and is competitive with state-of-the-art results on MPII [3].},
    language = {en},
    urldate = {2021-06-18},
    journal = {arXiv:1704.00159 [cs]},
    author = {Sun, Xiao and Shang, Jiaxiang and Liang, Shuang and Wei, Yichen},
    month = aug,
    year = {2017},
    note = {arXiv: 1704.00159},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
    file = {Sun et al. - 2017 - Compositional Human Pose Regression.pdf:/home/rafael/Zotero/storage/ZEIG53YS/Sun et al. - 2017 - Compositional Human Pose Regression.pdf:application/pdf}
}

@article{sarandi_synthetic_2018,
    title = {Synthetic {Occlusion} {Augmentation} with {Volumetric} {Heatmaps} for the 2018 {ECCV} {PoseTrack} {Challenge} on {3D} {Human} {Pose} {Estimation}},
    url = {http://arxiv.org/abs/1809.04987},
    abstract = {In this paper we present our winning entry at the 2018 ECCV PoseTrack Challenge on 3D human pose estimation. Using a fully-convolutional backbone architecture, we obtain volumetric heatmaps per body joint, which we convert to coordinates using soft-argmax. Absolute person center depth is estimated by a 1D heatmap prediction head. The coordinates are back-projected to 3D camera space, where we minimize the L1 loss. Key to our good results is the training data augmentation with randomly placed occluders from the Pascal VOC dataset. In addition to reaching ﬁrst place in the Challenge, our method also surpasses the state-of-the-art on the full Human3.6M benchmark when considering methods that use no extra pose datasets in training. Code for applying synthetic occlusions is availabe at https://github.com/ isarandi/synthetic-occlusion.},
    language = {en},
    urldate = {2021-06-18},
    journal = {arXiv:1809.04987 [cs]},
    author = {Sárándi, István and Linder, Timm and Arras, Kai O. and Leibe, Bastian},
    month = nov,
    year = {2018},
    note = {arXiv: 1809.04987},
    keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
    file = {Sárándi et al. - 2018 - Synthetic Occlusion Augmentation with Volumetric H.pdf:/home/rafael/Zotero/storage/KYWJ6V5F/Sárándi et al. - 2018 - Synthetic Occlusion Augmentation with Volumetric H.pdf:application/pdf}
}

@article{chen_monocular_2020,
    title = {Monocular {Human} {Pose} {Estimation}: {A} {Survey} of {Deep} {Learning}-based {Methods}},
    volume = {192},
    issn = {10773142},
    shorttitle = {Monocular {Human} {Pose} {Estimation}},
    url = {http://arxiv.org/abs/2006.01423},
    doi = {10.1016/j.cviu.2019.102897},
    abstract = {Vision-based monocular human pose estimation, as one of the most fundamental and challenging problems in computer vision, aims to obtain posture of the human body from input images or video sequences. The recent developments of deep learning techniques have been brought signiﬁcant progress and remarkable breakthroughs in the ﬁeld of human pose estimation. This survey extensively reviews the recent deep learning-based 2D and 3D human pose estimation methods published since 2014. This paper summarizes the challenges, main frameworks, benchmark datasets, evaluation metrics, performance comparison, and discusses some promising future research directions.},
    language = {en},
    urldate = {2021-06-18},
    journal = {Computer Vision and Image Understanding},
    author = {Chen, Yucheng and Tian, Yingli and He, Mingyi},
    month = mar,
    year = {2020},
    note = {arXiv: 2006.01423},
    keywords = {Computer Science - Computer Vision and Pattern Recognition},
    pages = {102897},
    file = {Chen et al. - 2020 - Monocular Human Pose Estimation A Survey of Deep .pdf:/home/rafael/Zotero/storage/TE5W9Z33/Chen et al. - 2020 - Monocular Human Pose Estimation A Survey of Deep .pdf:application/pdf}
}

@article{yang2020transpose,
    author = {Sen Yang and
 Zhibin Quan and
 Mu Nie and
 Wankou Yang},
    title = {TransPose: Towards Explainable Human Pose Estimation by Transformer},
    journal = {CoRR},
    volume = {abs/2012.14214},
    year = {2020},
    url = {https://arxiv.org/abs/2012.14214},
    archivePrefix = {arXiv},
    eprint = {2012.14214},
    timestamp = {Tue, 05 Jan 2021 16:02:31 +0100},
    biburl = {https://dblp.org/rec/journals/corr/abs-2012-14214.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{bulat2020skip,
    author = {Adrian Bulat and
 Jean Kossaifi and
 Georgios Tzimiropoulos and
 Maja Pantic},
    title = {Toward fast and accurate human pose estimation via soft-gated skip
 connections},
    journal = {CoRR},
    volume = {abs/2002.11098},
    year = {2020},
    url = {https://arxiv.org/abs/2002.11098},
    archivePrefix = {arXiv},
    eprint = {2002.11098},
    timestamp = {Tue, 03 Mar 2020 14:32:13 +0100},
    biburl = {https://dblp.org/rec/journals/corr/abs-2002-11098.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{su2019multi,
    author = {Zhihui Su and
 Ming Ye and
 Guohui Zhang and
 Lei Dai and
 Jianda Sheng},
    title = {Improvement Multi-Stage Model for Human Pose Estimation},
    journal = {CoRR},
    volume = {abs/1902.07837},
    year = {2019},
    url = {http://arxiv.org/abs/1902.07837},
    archivePrefix = {arXiv},
    eprint = {1902.07837},
    timestamp = {Tue, 21 May 2019 18:03:38 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1902-07837.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhao2019gcn,
    author = {Long Zhao and
 Xi Peng and
 Yu Tian and
 Mubbasir Kapadia and
 Dimitris N. Metaxas},
    title = {Semantic Graph Convolutional Networks for 3D Human Pose Regression},
    journal = {CoRR},
    volume = {abs/1904.03345},
    year = {2019},
    url = {http://arxiv.org/abs/1904.03345},
    archivePrefix = {arXiv},
    eprint = {1904.03345},
    timestamp = {Thu, 10 Oct 2019 17:03:18 +0200},
    biburl = {https://dblp.org/rec/journals/corr/abs-1904-03345.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{h36msinglecam,
    title = {{Papers With Code} Monocular 3D Human Pose Estimation on Human3.6M},
    howpublished = {\url{https://paperswithcode.com/sota/monocular-3d-human-pose-estimation-on-human3}},
    note = {Accessed: 2021-06-20}
}

@article{DBLP:journals/corr/HeZRS15,
    author = {Kaiming He and
 Xiangyu Zhang and
 Shaoqing Ren and
 Jian Sun},
    title = {Deep Residual Learning for Image Recognition},
    journal = {CoRR},
    volume = {abs/1512.03385},
    year = {2015},
    url = {http://arxiv.org/abs/1512.03385},
    archivePrefix = {arXiv},
    eprint = {1512.03385},
    timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
    biburl = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/XieGDTH16,
    author = {Saining Xie and
 Ross B. Girshick and
 Piotr Doll{\'{a}}r and
 Zhuowen Tu and
 Kaiming He},
    title = {Aggregated Residual Transformations for Deep Neural Networks},
    journal = {CoRR},
    volume = {abs/1611.05431},
    year = {2016},
    url = {http://arxiv.org/abs/1611.05431},
    archivePrefix = {arXiv},
    eprint = {1611.05431},
    timestamp = {Mon, 13 Aug 2018 16:45:58 +0200},
    biburl = {https://dblp.org/rec/journals/corr/XieGDTH16.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Everingham2009ThePV,
    title={The Pascal Visual Object Classes (VOC) Challenge},
    author={M. Everingham and L. Gool and Christopher K. I. Williams and J. Winn and Andrew Zisserman},
    journal={International Journal of Computer Vision},
    year={2009},
    volume={88},
    pages={303-338}
}